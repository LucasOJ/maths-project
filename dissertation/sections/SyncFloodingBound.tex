\section{Bounding the synchronous flooding time}
\label{SyncFloodingSection}

\subsection{Model}

\begin{definition} \label{SyncFloodingAlgorithm}
	Synchronous Flooding Rumour Spreading Algorithm

	\noindent
	The synchronous rumour spreading algorithm proceeds in rounds on a dynamic network $\mathcal{G} = (G_t)_{t \in \mathbb{N}}$. Initially a single node is aware of the rumour. In round $i$, every node that is aware of the rumour informs all of its neighbours in $G_i$, regardless of whether they already knew the rumour or not.
\end{definition}

We note that the asynchronous rumour spreading algorithm (algorithm \ref{NodeCentricAsyncAlgorithm}) was probabilistic since the algorithm depended on sources of randomness such as exponential clocks. In contrast, once the dynamic network and initial node from which the rumour spreads are chosen, algorithm \ref{SyncFloodingAlgorithm} is entirely deterministic. Since the trajectory of the rumour spread is completely determined by the initial conditions, it is reasonable to question why we would want bounds on the spreading time if we can simply simulate the rumour, and record how long it takes to inform all the nodes. However, some graphs may be so large that simulation is computationally infeasible. In such cases we need bounds in terms of the structural properties of graphs instead. Additionally, in section \ref{subsection:MEDNBound}
we analyse rumour spreading on a non-deterministic dynamic network, where the sequence of graphs is not fixed but instead follows some distribution. In this case, deterministic bounds will allow us to make claims about the spreading time over the distribution of graph sequences.

% TODO: Why study flooding time?
% Flooding only works for synchronus

\begin{definition}
	$(h, k)$-Expander

	\noindent
	A graph $G$ on a vertex set $V$ is a $(h, k)$-expander if for all subsets of nodes $S \subseteq V$ such that $|S| \leq h$ satisfy $|N(I)| \geq k$.
\end{definition}

\begin{definition}
	Boundary set $B(S)$

	\noindent 
	Given a graph $G=(V,E)$, the boundary set $B(S)$ of a vertex subset $S \subseteq V$ is defined as the set of vertices outside $S$ connected to a node of $S$ by an edge, i.e
	$$
		B(S) = \left\{u \in V \setminus S : \{u, v\} \in E \text{ for some } v \in S \right\}
	$$
\end{definition}

\subsection{Deriving the Deterministic Flooding Bound}

First we give a bound on the rumour spreading time for a deterministic sequence of graphs. 

\begin{theorem}\label{theorem:DeterministicFloodingBound}
	\ModelIntro Suppose also that there exists an increasing sequence $1 = h_0 \leq h_1 < \dots < h_s = \frac{n}{2}$ and decreasing sequence $k_1 \geq k_2 \geq \dots \geq k_s$ of positive real numbers, such that for all $t \in \mathbb{N}$, $G_t$ is a $(h_i, k_i)$-expander for every $i \in \{1, \dots , s\}$. Then the spreading time of $\mathcal{G}$ under algorithm \ref{SyncFloodingAlgorithm} is
	$$
		\mathcal{O}\left(\sum_{i=1}^s \frac{\log \frac{h_i}{h_{i-1}}}{\log(1+k_i)}\right)
	$$
\end{theorem}

% TODO: Strength of assumptions, why bother considering?

\begin{proof}
	For $i = 1,\dots, s$, let $T_i$ be the earliest time step such that the number of informed nodes is larger than $h_i$, i.e

	$$
		T_i = \min \{ t \in \mathbb{N} : |I_t| > h_i \}
	$$

	First we bound the number of steps in the interval $[T_{i-1}, T_i]$. If $T_{i-1} = T_i$ then the length of the interval is trivially 0, so suppose instead that $T_{i-1} < T_i$.

	By induction, we show that if $T_{i-1} + t < T_i$, then the number of informed nodes at time $T_{i-1} + t$ is greater than $(1+k_i)^t h_{i-1}$.
	
	\underline{Base Case.} Suppose that $t=0$. 
	
	Then by the definition of $T_{i-1}$, the number of informed nodes at time $T_{i-1}$ is strictly greater than $h_{i-1}$

	\underline{Inductive Case.} Suppose that $|I_{T_{i-1} + t}| > (1+k_i)^t h_{i-1}$.

	For brevity, let $s = T_{i-1} + t$. We notice that 
	% TODO: Justify steps
	% TODO: Define boundary of S, B(S)
	\begin{align*}
		|I_{s+1}| &= |I_s| + |B(I_s)| \\ %by operation of algo
		& \geq |I_s| + k_i |I_s| \\ % since we assume s < T_i => |I_s| \leq h_s + (h_s, k_s)-expander
		& = (1 + k_i)|I_s| \\
		& > (1 + k_i)(1+k_i)^t h_{i-1} \\ % by induction hypotheis
		& = (1+k_i)^{t+1} h_{i-1}
	\end{align*}
	% TODO: boundary set picture here	
	Let $\tau = T_{i-1} + \ceil{ \frac{\log (h_i/h_{i-1})}{\log(1+k_i)}}$. 
	Suppose for contradiction that $\tau < T_i$. %TODO: Is contradicition overkill here?
	Since we assumed $\tau < T_i$ we can apply the above inequality %TODO: label
	to get that 
	$$
		|I_\tau| > 
		(1+k_i)^{\ceil{ \frac{\log (h_i/h_{i-1})}{\log(1+k_i)}}} h_{i-1}
		\geq e^{\log (h_i/h_{i-1})} h_{i-1}
		= h_i
	$$
	Thus we have a contradiction since the number of informed nodes at time $\tau$ is greater than $h_i$, so $\tau \geq T_i$. Rearranging this inequality gives us the following bound on the length of the interval $[T_{i-1}, T_i]$:
	\begin{equation} \label{eq:FloodingSingleStepBound}
		T_i - T_{i-1} \leq \ceil{ \frac{\log (h_i/h_{i-1})}{\log(1+k_i)}} \leq \frac{\log (h_i/h_{i-1})}{\log(1+k_i)} + 1
	\end{equation}
	% TODO: Make ceiling brackets fit
	% TODO: Exposition about next steps + direction here
	We now apply our bound in two cases

	\textbf{Case 1.} Suppose $\frac{\log (h_i/h_{i-1})}{\log(1+k_i)} \geq 1$.

	In this case $\frac{\log (h_i/h_{i-1})}{\log(1+k_i)}$ term is the dominant term in inequality (\ref{eq:FloodingSingleStepBound}), thus
	$$
		T_i - T_{i-1} = \mathcal{O}\left( \frac{\log (h_i/h_{i-1})}{\log(1+k_i) }\right) + \mathcal{O}(1) = \mathcal{O}\left( \frac{\log (h_i/h_{i-1})}{\log(1+k_i) }\right)
	$$

	\textbf{Case 2.} Suppose $\frac{\log (h_i/h_{i-1})}{\log(1+k_i)} < 1$.

	In this case we cannot achieve the same bound on $T_i - T_{i-1}$, since the additive 1 is the dominant term. By following the same reasoning as in Case 1, we can only obtain
	\begin{equation}\label{eq:Weak1StepBound}
		T_i - T_{i-1} = \mathcal{O}\left( \frac{\log (h_i/h_{i-1})}{\log(1+k_i) }\right) + \mathcal{O}(1) = \mathcal{O}(1)
	\end{equation}
	To understand why this bound is weak, and derive a stronger one, we inspect the inequality we assumed in this case. % TODO: link back to this 
	By rearranging we find that $(1+k_i)h_{i-1} > h_i$. Since the minimum number of informed nodes after round $T_{i-1}$ is $(1+k_i)h_{i-1}$, we see that the number of informed nodes "jumps" to more than $h_i$ nodes in a single time step. % TODO: Wrong, fix this

	It may be that after this jump there are also more than $h_{i+k}$ nodes for some $k \geq 0$, from which we obtain $T_i = \dots = T_{i+k}$. In this case the total time that has passed between $T_{i-1}$ and $T_{i+k}$ is 0. However, using equation (\ref{eq:Weak1StepBound}) to bound even the first increment $T_{i-1}$ to $T_i$ gives the bound of $\mathcal{O}(1)$. We would prefer a much tighter bound, so instead bound the whole jump interval as follows. %TODO: Reprase end of this sentance
	
	% TODO: j doesn't exist case
	Let $j$ be the index such that $h_{j-1} < (1+k_i)h_{i-1} \leq h_j$, i.e the first $j \geq i$ when $T_j \neq T_{i-1}$. % TODO: Check this equivalence

	Note that from rearranging the definition of j
	\begin{align*}\label{eq:JumpBoundGeq1}
		1 &\leq \frac{\log (h_j) - \log(h_{i-1})}{\log(1+k_i) } \\
		& =\sum_{l=i}^j \frac{\log (h_{l}) - \log(h_{l-1})}{\log(1+k_i) } & \text{since the numerator forms a telescoping sum} \\
		& \leq \sum_{l=i}^j \frac{\log (h_{l}/h_{l-1})}{\log(1+k_l) } & \text{since the } k_i \text{s are a decreasing sequence and } i \leq l
	\end{align*}
	
	Hence, we can bound the length of the interval $[T_{i-1}, T_j]$ as follows.
	\begin{align*}
		T_j - T_{i-1} &= T_j - T_{j-1} & \text{since by the definition of j } T_{i-1} = T_{j-1}\\
		& \leq \frac{\log (h_j/h_{j-1})}{\log(1+k_i)} + 1 & \text{by applying inequality }(\ref{eq:FloodingSingleStepBound}) \\
		& \leq \frac{\log (h_j/h_{i-1})}{\log(1+k_i)} + 1 & \text{since the } h_i \text{s are increasing and } j \geq i \\
		& \leq \sum_{l=i}^j \frac{\log (h_{l}/h_{l-1})}{\log(1+k_l) } + 1 & \text{ by the previous inequality chain} \\
		& = \mathcal{O}\left(\sum_{l=i}^j \frac{\log (h_{l}/h_{l-1})}{\log(1+k_l) }\right)
 	\end{align*}
	where the final equality holds since by the previous inequality chain, the summation is greater than 1, so is the dominant term.

	We now use this equality to bound the growth of $T_s$, the first time at which more than $h_s = \frac{n}{2}$ nodes are aware of the rumour. We can express $T_s$ as a telescoping sum of intervals as follows:
	$$
		T_s = \sum_{i=1}^s T_i - T_{i-1}
	$$
	For the $i^\text{th}$ interval, if $\frac{\log (h_i/h_{i-1})}{\log(1+k_i)} \geq 1$, i.e. it takes at least one step then we can apply the bound from Case 1.
	
\end{proof}

\subsection{Review of Markov Chains}

\begin{enumerate}
	\item Definition
	\item Stationary distribution definition and Interpretation
\end{enumerate}

\subsection{Generalising the bound to Markovian Evolving Dynamic Networks}
\label{subsection:MEDNBound}

\begin{definition}
	Markovian Evolving Dynamic Network (MEDN)

	\noindent 
	Let $A_n$ be the set of all possible graphs on n vertices.
	A Markovian Evolving Dynamic Network is a random sequence of graphs $\mathcal{M} = (G_t)_{t \in \mathbb{N}}$ indexed by an integer time $t$, such that $\mathcal{G}$ is a Markov chain with state space $A_n$.
\end{definition}

We say that a given MEDN $\mathcal{M}$ is stationary if the distribution of $G_0$ is a stationary distribution of $\mathcal{M}$. By the definition of a stationary distribution, in such an MEDN the probability that $G_t = G'$ for a given $G'$ is the probability that $G_t = G'$ under the stationary distribution, for any time step $t$. Hence, the evolution of the network essentially proceeds by independently sampling a topology from the stationary distribution at each time step. % TODO: Check if independent, get rid of "essentially"?

% TODO: Is this a non-theorm? What does it acutally mean?

\begin{theorem}
	Let $\mathcal{M} = (G_t)_{t \in \mathbb{N}}$  be a stationary Markovian evolving graph. Suppose also that there exists an increasing sequence $1 = h_0 \leq h_1 < \dots < h_s = \frac{n}{2}$ and decreasing sequence $k_1 \geq k_2 \geq \dots \geq k_s$ of positive real numbers, such that with probability $1-\frac{1}{n^2}$, the stationary distribution of $\mathcal{M}$ is a $(h_i, k_i)$-expander for every $i \in \{1, \dots , s\}$. Then the spreading time of $\mathcal{G}$ under algorithm \ref{SyncFloodingAlgorithm} is
	$$
		\mathcal{O}\left(\sum_{i=1}^s \frac{\log \frac{h_i}{h_{i-1}}}{\log(1+k_i)}\right)
	$$
	with high probability.
\end{theorem}

We notice that in this theorem, instead of requiring every graph topology to satisfy the expansion conditions of Theorem \ref{theorem:DeterministicFloodingBound}, we only require that the expansion properties hold with high probability with respect to the stationary distribution. Since each topology is sampled from the stationary distribution, these properties will hold for nearly all the topologies in the sequence. Thus, this theorem states that our deterministic bound will still hold, as long as the long-term proportion of topologies in our network without strong expansion properties is bounded by $\frac{1}{n^2}$.

% TODO: Review this proof for order that makes sense, and check it actually holds

\begin{proof}
	For all $t \in \mathbb{N}$, let $A_t$ be the event that $G_t$ is an $(h_i, k_i)$-expander for all $1 \leq i \leq s$. Since $\mathcal{M}$ is stationary, we have that $\mathbb{P}(A_t) \geq 1 - \frac{1}{n^2}$ for all t. 

	Let $B$ denote the event we are interested in, namely that the rumour spreading time is 	
	$$
		\mathcal{O}\left(\sum_{i=1}^s \frac{\log \frac{h_i}{h_{i-1}}}{\log(1+k_i)}\right)
	$$

	Suppose that $A_k$ holds for all $k \leq n$. We claim that the rumour spreads in at most $n$ time steps with certainty. Since we have assumed that all topologies up to time $n$ are $(h_1, k_1)$-expanders, there are no isolated nodes, as such an isolated node $v$ would form a subset of size $1 \leq h_1$ with $B({v}) = 0 < k_1$, a contradiction. Thus, the network is connected for the first $n$ time steps. Hence, for any time step $t \leq n$ before all nodes are informed of the rumour, $B(I_t) \geq 1$, since there is only 1 connected component so $I_t$ must be connected  to $U_t$ by at least 1 edge. It follows that in each time step at least 1 new node becomes informed of the rumour by the operation of algorithm \ref{SyncFloodingAlgorithm}. Hence, at most $n$ steps are needed to spread the rumour when $A_k$ holds for all $k \leq n$. 

	Let $T$ denote the first time step at which all nodes are informed of the rumour. By Theorem \ref{theorem:DeterministicFloodingBound} we have that if $A_k$ holds for all $k \leq T$, then $T=\mathcal{O}\left(\sum_{i=1}^s \frac{\log (h_i/h_{i-1})}{\log(1+k_i)}\right)$, as once all the nodes have been informed, the expansion properties of the remaining topologies are irrelevant.

	Now we combine the previous two claims. By the first claim if $A_k$ holds for all $k \leq n$ we have that $T \leq n$, thus $A_k$ holds for all $k \leq T$. In this case, by the second claim we obtain that  $T=\mathcal{O}\left(\sum_{i=1}^s \frac{\log (h_i/h_{i-1})}{\log(1+k_i)}\right)$.

	Since we have shown that the event $\bigcap_{t=0}^n A_t \implies B$, we have that $\comp{B} \implies \comp{ \bigcap_{t=0}^n A_t} = \bigcup_{t=0}^n \comp{A_t}$. To finish the proof, we show that the event $\comp{B}$ happens with vanishing probability, thus $B$ happens with high probability.

	\begin{align*}
		\mathbb{P}(\comp{B}) &\leq \mathbb{P}(\bigcup_{t=0}^n \comp{A_t}) & \text{by the inferred implication} \\ 
		& \leq n \mathbb{P}(\comp{A_t}) & \text{by the union bound}\\ 
		& \leq n \frac{1}{n^2} = \frac{1}{n} & \text{by the conditions on the stationary distribution}
	\end{align*}

	% TODO: THINK ABOUT h_0

\end{proof}

\subsection{Applying the bound to Edge-Markovian evolution}

TODO: Prove that stationary distribution of edge-markovian evolution is ER G(n, p/(p+q))

\begin{theorem}
	Let $\mathcal{M}(n, p, q)$ be an Edge-Markovian Dynamic Network in its stationary distribution. If $p \geq c \frac{\log n}{n}$ for a sufficiently large $c$ then with high probability, the flooding time in $\mathcal{M}(n, p, q)$ is 

	$$
		\mathcal{O}\left(\frac{\log n}{\log np} + \log \log np \right)
	$$
\end{theorem}

TODO: Proof

\begin{proof}
	
\end{proof}

% TODO: What happens if p < c logn/n?
% lower bound on mixing time
% TODO: Why can't generalise to varying t? (Non-homogenous MC)

\subsection{Simulations}

TODO: Evaluate tightness of bound for Edge-Markovian evolution