\documentclass[a4paper,11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{mathtools}

%you can add more packages using the same code above

%------------------

%\setlength{\topmargin}{0.0in}
%\setlength{\textheight}{10in}
%\setlength{\oddsidemargin}{0.0in}
%\setlength{\evensidemargin}{0.0in}
%\setlength{\textwidth}{6.5in}

%-------------------


\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}


\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem*{example}{Example}

\newcommand*\comp[1]{\overline{#1}}

\newcommand{\lb}{\left}
\newcommand{\rb}{\right}
\newcommand{\ModelIntro}{
	Let $\mathcal{G} = (G_t)_{t \in \mathbb{N}}$ be an $n$-node dynamic network, where one node is aware of a rumour in $G_0$.
}


\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\allowdisplaybreaks
%------------------

%Everything before begin document is called the pre-amble and sets out how the document will look
%It is recommended you don't touch the pre-amble until you are familiar with LateX

\begin{document}

\input{coverpage.tex}


\begin{abstract}
	TODO
\end{abstract}
	
	
\tableofcontents


\section{Introduction}

Dynamic networks are complex networks which change over time. The study of such structures is important as we can use them to model many important real-world situations[CITE]. For example, computer networks such as the internet are dynamic: connections between nodes can fail and new nodes can be added which leads to an ever-changing network topology. 

In this paper we investigate a variety of randomized rumour spreading algorithms on dynamic networks. In these algorithms initially a single node is aware the rumour, which spreads randomly between nodes along present edges. These algorithms model important phenomenons such as epidemics spreading through a population [CITE], and distributed databases replicating their state across a network [CITE]. 

% TODO: FOLLOWING IS WRONG - ALSO CONSIDERING FLOODING TIME
We compare rumour spreading algorithms by deriving the time it takes for the rumour to spread to all nodes on a given dynamic network, known as the rumour spreading time. Since the algorithms we consider are randomized, the rumour spreading time will vary. Hence, the best we can do is we find bounds that hold with high probability. Such bounds are well-known for static networks [CITE - complex networks unit], but in this paper we extend these results to networks with changing topologies. For simplicity, we restrict our investigations to dynamic networks where the edges may be introduced or removed over time, but the vertex set remains the same.

In Section \ref{Prelims} we introduce the notation and background needed to model rumour spreading.

In Section \ref{AsyncUpperBoundSection} we specify an asynchronous rumour spreading algorithm and review a result by [CITE] which bounds its associated spreading time on a dynamic network. In this analysis the exact changes in network topology are known before the rumour spreading takes place, however in practice this assumption may be unrealistic.

In Section \ref{section:AsyncLowerBound} we review the complementary result from the same paper that the asynchronous bound is almost tight.

In Section \ref{SyncFloodingSection} we investigate the flooding time for a synchronous rumour spreading algorithm, following results of a paper by [CITE]. We loosen the assumption that we know the exact changes to the network topology at each time step, by instead considering a model where changes occur according to a given probability distribution.

In Section \ref{AsyncCheegerBound} we combine ideas from sections \ref{AsyncUpperBoundSection} and \ref{SyncFloodingSection} to derive a novel bound on the rumour spreading time of an asynchronous algorithm. 

% TODO - finish this

\begin{enumerate}
	\item Motivation for studying
	\item Structure of paper
	\item Results proved
	\item My contributions
\end{enumerate}

\section{Preliminaries}
\label{Prelims}

\subsection{Notation}

First we introduce notation for expressing graph metrics. This notation will also be used throughout the paper. % TODO - GET RID OF SECOND LINE?

\begin{definition}
	Complement Set

	\noindent
	Given a graph $G = (V, E)$, for a set of vertices $S \subseteq V$ we define the complement set $\comp{S} = V \setminus S$
\end{definition}

\begin{definition}
	Cut Set

	\noindent
	Given a graph $G = (V, E)$, for a set of vertices $S \subseteq V$ we define the cut set $ E(S, \comp{S}) = \left\{\{u, v\} \in E \mid u \in S, v \in \comp{S} \right\}.$
\end{definition}

\begin{definition}
	Degree of a vertex

	\noindent
	Given a graph $G = (V, E)$, let $d_v$ be the number of neighbouring nodes $v$ is adjacent to, i.e. $$
		d_v = |\left\{ e \in E : v \in e \right\}|
	$$
\end{definition}

\begin{definition}
	Volume of a vertex set

	\noindent
	Given a graph $G = (V, E)$ with $S \subseteq V$, let 
	$$
		\text{vol}(S) = \sum_{v \in S} d_v
	$$
\end{definition}

% TODO: Explain Implications of Cut set defn?

\subsection{Graph Metrics}

\begin{definition}
	Conductance of a graph $G = (V, E)$

	$$
		\Phi(G) = \min_{\emptyset \neq S \subset V} \frac{|E(S, \comp{S})|}{\min\{\text{vol}(S), \text{vol}(\comp{S})\}}
	$$
\end{definition}

\begin{definition}
	Diligence of a cut $ E(S, \comp{S}) $
	$$
		\rho(S) = \comp{d}(S) \min_{\{u, v\} \in E(S, \comp{S}) } \left\{ \max \left\{ \frac{1}{d_u},\frac{1}{d_v} \right\} \right\}
	$$ 

	where $\comp{d}(S) := \frac{\sum_{v \in S} d_v}{|S|}$ is the average degree of the vertices in $S$
\end{definition}

\begin{definition}
	Diligence of a graph $G$
	$$
		\rho(G) = \min_{S \in V} \rho(S) 
	$$
\end{definition}

\subsection{Introducing Dynamic Networks}

Here we formally define the Dynamic Network structure rumours will spread on.

\begin{definition}
	Dynamic Network

	\noindent
	A dynamic network is a sequence of graphs $\mathcal{G} = (G_t)_{t \in \mathbb{N}}$ indexed by an integer time $t$. All the graphs in the sequence have the same vertex set at each time step, but the edge set may vary, i.e.  $G_t = (V, E_t)$ where $E_t$ is some edge set on $V$.
\end{definition}

$G_t$ represents the topology of the network at the discrete time step $t$. However, asynchronous rumour spreading algorithms operate in continuous time, so we need to define the topology of the network at non-integer times. To represent the state of the network at any non-negative continuous time $\gamma \in \mathbb{R}_+$, we say that the current network topology $G_\gamma$ := $G_{\floor\gamma}$. Thus, for any time $\gamma \in [t, t + 1)$ the network topology is fixed to $G_t$. This corresponds to allowing the network topology change at integer time steps only.

% TODO: Segway

\begin{definition}
	Vertex degree at time $\gamma \in \mathbb{R}_+ $ 

	\noindent
	For a Dynamic Network $\mathcal{G}$ on a vertex set $V$, $d_v(\gamma)$ is the degree of a vertex $v \in V$ at time $\gamma$, i.e. the degree of $v$ in $G_\gamma$
\end{definition}


\subsection{Review of Poisson Processes}

In this subsection we introduce Poisson processes, which will be needed to specify the first asychronous rumour spread algorithm.

The Poisson process ...

TODO

\begin{enumerate}
	\item Definition
	\item $N(s + t) - N(s)$ has a Poisson distribution with rate $\lambda t$
	\item Superposition
\end{enumerate}


\subsection{Order statistics of exponential random variables}

TODO: Prove that minimum of exponentials is exponential, where the probability each exponential that attains the minimum is dependent on each exponentials' rate, and independent of the value of the min

% TODO: Discuss implications for async rumour spreading - interpreting poission process as exponential clock, not interested in value of the process

\section{Upper bounding the asynchronous rumour spreading time}
\label{AsyncUpperBoundSection}

\subsection{Introducing the Rumour Spreading Model}
Now we are ready to define our first asynchronous algorithm for rumour spreading on a given dynamic network.

\begin{definition}
	Push-Pull Asynchronous Rumour Spreading Algorithm 
\end{definition}
\label{NodeCentricAsyncAlgorithm}

\noindent
An asynchronous rumour spreads on a given dynamic network $\mathcal{G} = (G_t)_{t\in \mathbb{N}}$ in rounds. Initially a single node is aware of the rumour. In round $t$, each node aware of the rumour is associated with a unit rate exponential clock. When the of clock of an informed node $u$ ticks, another node $v$ is selected uniformly at random from the set of neighbouring nodes in $G_t$. $u$ then instantaneously informs $v$ of the rumour if $v$ was not already informed. Each round lasts for a unit time. % TODO: Change final line

% TODO: This is wrong - push and pull model

% TODO: DEFINE 'UNIT RATE CLOCK' and how it functions (eg what happens after infomed a node)

% TODO: What happens in the case where the node has no neighbours?

% TODO: Implications of this model

\subsection{Result and Proof}

First we prove a lemma about how long it takes for the number of nodes aware of the rumour to increase by a multiplicative factor. 

\begin{lemma} \label{AsyncIncreaseLemma}
	Let $\mathcal{G}=(G_t)_{t \in \mathbb{N}}$ be an $n$-node dynamic network. At $t=0$ a single node is aware of rumour which spreads according to algorithm \ref{NodeCentricAsyncAlgorithm}. Choose an arbitrary time $\tau \in [0, \infty)$. We denote the set of informed nodes at this time $I_\tau$, and set uninformed nodes $U_\tau$.
	\noindent
	Define 
	
	$$
	\Delta(\alpha) = \min \left\{t: \sum_{k=0}^t \Phi(G_{\ceil{\tau}+k})\rho(G_{\ceil{\tau}+k}) \geq 2 \alpha \right\}
	$$

	\noindent
	Let $\tau'$ denote the earliest time when $|I_t|$ increases by $\frac{m(\tau)}{2}$, where $m(\tau) := \min\{|I_\tau|, |U_\tau|\}$, i.e,

	$$
		\tau' = \min\left\{\gamma : |I_{\gamma}| \geq |I_\tau| + \frac{m(\tau)}{2}\right\}
	$$
	\noindent
	Then, 
	$$
		\mathbb{P}(\tau' - \tau \geq \Delta(\alpha) + 2) \leq e^{-c\alpha m(\tau)}
	$$
	\noindent
	where $c = \frac{1}{2} - \frac{1}{e}$
\end{lemma}

% TODO: Exposition about interpretation here, dependeces (ie what is m(t) dependent on? et)

At first sight, it may be difficult to identify the relationship that this lemma expresses, so we first explore the implications of the result before moving to the proof.

When less than half of the nodes are informed of the rumour, we can interpret $\tau'$ as the first time at which the number of informed nodes increases by a half, compared to number of informed nodes at time $\tau$. In this case $|I_{\tau'}| \approxeq \frac{3}{2} |I_\tau|$. Conversely, when more than half of the nodes are informed, $\tau'$ is the first time at which the set of uniformed nodes shrinks in size by a half, i.e $|U_{\tau'}| \approxeq \frac{|U_\tau|}{2}$. Thus, the random quantity of interest $\tau'-\tau$ is the amount of time it takes for the number of informed nodes to expand by a multiplicative factor, from time $\tau$. 

In the lemma we are interested in the event that this time exceeds $\Delta(\alpha) + 2$. 
The  $+2$ arises from technicalities in the proof, however the $\Delta(\alpha)$ term reveals a relationship between to the rate at which the set of informed nodes expands, and the connectivity of the dynamic network. % TODO: Change the end of this sentance?
Suppose we fix $\alpha$ and $\tau$. From the definition of $\Delta(\alpha)$ we see that the greater the conductance and diligence metrics of the static topologies in the time steps immediately after $\tau$, the smaller the value of $\Delta(\alpha)$ becomes, since the summation will exceed $2\alpha$ in fewer terms. Thus, we see that well-connected topologies will yield smaller values of $\Delta(\alpha)$. Returning to the probability bound, we see that the bounding term $e^{-c\alpha m(\tau)}$ is independent of the topologies after $\tau$. Thus the bound tells us that the better the connectivity, the shorter the time it takes for the rumour to spread by a multiplicative factor (under the same probability). % TODO: Change bracketed bit to make more sense or remove
This supports our intuitive expectation that rumour spreading using algorithm \ref{NodeCentricAsyncAlgorithm} is faster in well-connected dynamic networks. % TODO: SHOULD WE EXPECT THIS? HIGHER CONNETIVITY => HIGER DEGREE => LOWER RATE OF TRANSMISSION BETWEEN INDIVIUDAL PAIRS OF NODES.

% TODO: Sanity check on bound by varying alpha: larger alpha => larger delta(alpha) => stronger bound below => tighter proabilitstic bound e^stuff


\begin{proof}
	Fix a time $\gamma \in [\tau, \tau')$. 
	We consider the set of edges $E(I_\gamma, U_\gamma)$ between the informed and uninformed sets of nodes at time $\gamma$. 
	For every $\{u, v\} \in E(I_\gamma, U_\gamma)$, node $u$ pushes the rumour to $v$ according to a Poisson process of rate $\frac{1}{d_u(\gamma)}$ % TODO: Why does this hold?
	Thus the time until the first uniformed node is made aware of the rumour has an exponential distribution of rate % TODO: Why does this hold
	$$
		\lambda(\gamma) = \sum_{\{u, v\} \in E(I_\gamma, U_\gamma)} \frac{1}{d_u(\gamma)}
	$$
	% TODO: DIAGRAM HERE LABELLED WITH RATES
	Let $S = I_\gamma$ if $\text{vol}(I_\gamma) \leq \text{vol}(I_\gamma)$, otherwise let $S = U_\gamma$. Then,

	%TODO: Justify all steps
	\begin{align*}
		\lambda(\gamma) &= \sum_{\{u', v'\} \in E(I_\gamma, U_\gamma)} \left\{ \frac{1}{d_{u'}(\gamma)} + \frac{1}{d_{v'}(\gamma)} \right\}\\
		& \geq \sum_{\{u', v'\} \in E(I_\gamma, U_\gamma)}  \max \left\{ \frac{1}{d_{u'}(\gamma)},\frac{1}{d_{v'}(\gamma)} \right\} \\ 
		% TODO: Justify above
		& \geq \sum_{\{u', v'\} \in E(I_\gamma, U_\gamma)} \min_{\{u, v\} \in E(I_\gamma, U_\gamma) } \left\{ \max \left\{ \frac{1}{d_u(\gamma)},\frac{1}{d_v(\gamma)} \right\} \right\} & \\ 
		& = \min_{\{u, v\} \in E(I_\gamma, U_\gamma) } 
		\left\{ \max \left\{ \frac{1}{d_u(\gamma)},\frac{1}{d_v(\gamma)} \right\} \right\} |E(I_\gamma, U_\gamma)| \\
		%TODO: Mention degrees indexed by time above?
		& = \rho(S) \frac{|S|}{\text{vol}(S)} |E(I_\gamma, U_\gamma)| \\
		& = \rho(S) |S| \frac{|E(I_\gamma, U_\gamma)|}{ 
			\min\{\text{vol}(I_\gamma), \text{vol}(U_\gamma)\}
		} \\
		& \geq \rho(G_\gamma)\Phi(G_\gamma)|S| \\ 
		% TODO: Since We instantiate at specific sets
		& \\
		& \geq \rho(G_\gamma)\Phi(G_\gamma) \min\{|I_\gamma|, |U_\gamma|\} \\
		& \text{since } S = I_\gamma \text { or } U_\gamma \\
		& \\
		& = \rho(G_\gamma)\Phi(G_\gamma) m(\gamma) \\
		& \text{by the definition of } m(\gamma)
	\end{align*}
	% TODO: Brief exposition here
	We now procceed to prove the following claim, by performing case analysis on $m(\gamma)$

	\textbf{Claim.} $m(\gamma) \geq \frac{m(\tau)}{2}$. % Inutive explanation

	\textbf{Case 1.} Suppose $m(\gamma) = |I_\gamma|$

	\noindent
	Once a node is aware of the rumour it never becomes uninformed. Hence, as $\tau \leq \gamma$, at time $\gamma$ there are at least $|I_\tau|$ informed nodes, thus 
	$$
	|I_\gamma| \geq |I_\tau| \geq \frac{|I_\tau|}{2} \geq \frac{m(\tau)}{2}
	$$
	so the claim holds in this case.

	\textbf{Case 2.} Suppose instead that $m(\gamma) = |U_\gamma|$

	\noindent
	By the defintion of $\tau'$, since $\gamma < \tau'$ we have that $|I_{\gamma}| < |I_\tau| + \frac{m(\tau)}{2}$.

	Since $|I_t| + |U_t| = n$ for all times $t$, note that
	$$
		|I_{\gamma}| < |I_\tau| + \frac{m(\tau)}{2} 
		\iff
		n - |U_{\gamma}| < n - |U_\tau| + \frac{m(\tau)}{2} 
		\iff
		|U_\gamma| > |U_\tau| - \frac{m(\tau)}{2}
	$$
	Thus we have that
	\begin{align*}
		|U_\gamma| & > |U_\tau| - \frac{m(\tau)}{2} & \text{since }\gamma < \tau' \\
		& \geq |U_\tau| - \frac{|U_\tau|}{2} & \text{since } m(\tau) \leq |U_\tau| \\
		& = \frac{|U_\tau|}{2} \\
	\end{align*}
	Thus the claim holds in this case also.
	
	\noindent
	By applying the claim to the final inequality in the previous chain of inequalities we get that
	\begin{equation} \label{eq:RateBound}
		\lambda(\gamma) \geq \rho(G_\gamma)\Phi(G_\gamma)\frac{m(\tau)}{2}
	\end{equation}

	So far we have bounded the rate at which uninformed nodes are made aware of the rumour at time $\gamma$. Since the rate of transmission is a function of $\gamma$ we define an inhomogeneous Poisson process $\{N(\gamma), \gamma \geq \tau\}$ with rate function $\lambda(\gamma)$. Intuitively, $N(\gamma)$ counts the number of newly informed nodes in the interval $[\tau,\gamma)$. %TODO: Change last sentance - exactly the same as paper


	By [CITE INHOMOGENOUS THEROEM], $N(\tau + \Delta(\alpha) + 2)$ has a Poission distribution with rate $\Lambda(\tau + \Delta(\alpha) + 2)$, where
	\begin{align*}
		\Lambda(\tau + \Delta(\alpha) + 2) &= \int_\tau^{\tau + \Delta(\alpha) + 2} \lambda(\gamma) d\gamma \\
		& \geq \int_{\ceil\tau}^{{\ceil\tau} + \Delta(\alpha) + 1} \lambda(\gamma) d\gamma \\
		& \text{since } \lambda(\gamma) \geq 0 \text{ as it is a rate function}\\
		& \\
		& = \sum_{k=0}^{\Delta(\alpha)} \int_{\ceil\tau + k}^{{\ceil\tau} + k + 1} \lambda(\gamma) d\gamma \\
		& \text{by splitting the integral into unit length intervals } \\
		& \\
		& = \sum_{k=0}^{\Delta(\alpha)} \int_{\ceil\tau + k}^{{\ceil\tau} + k + 1} \rho(G_\gamma)\Phi(G_\gamma)\frac{m(\tau)}{2} d\gamma \\
		& \text{by applying Inequality } \ref{eq:RateBound} \\
		& \\
		& = \sum_{k=0}^{\Delta(\alpha)} \rho(G_{\ceil\tau + k})\Phi(G_{\ceil\tau + k})\frac{m(\tau)}{2} \\
		& \text{since } G_\gamma = G_{\floor\gamma} \\
		& \\
		& \geq 2\alpha\frac{m(\tau)}{2} \\
		& \text{by the definition of } \Delta(\alpha) \\
		& \\
		& = \alpha m(\tau)
	\end{align*}
	Let $X$ be a random variable with a $\text{Poisson}(\alpha m(\tau))$ distribution. 
	By the previous chain of inequalities we have that $X$ is stochastically dominated by $N(\tau + \Delta(\alpha) + 2)$. % TODO: Talk about stochastic domination
	Note that
	$$
		\tau' - \tau \geq \Delta(\alpha) + 2 \iff 
		\tau' \geq \tau + \Delta(\alpha) + 2 \implies 
		N(\tau + \Delta(\alpha) + 2) \leq \frac{m(\tau)}{2}
	$$
	where the final implication holds since by the definition of $\tau'$, if $\tau' \geq \tau + \Delta(\alpha) + 2$ then the number of new nodes informed of the the rumour between time $\tau$ and $\tau + \Delta(\alpha) + 2$ must be less than or equal to $\frac{m(\tau)}{2}$. Hence we have that
	\begin{align*}
		\mathbb{P}(\tau' - \tau \geq \Delta(\alpha) + 2) & 
		\leq \mathbb{P} (N(\tau + \Delta(\alpha) + 2) \leq \frac{m(\tau)}{2}) \\ %TODO: Make () brackets large
		& \leq \mathbb{P}(X \leq \frac{m(\tau)}{2}) \\
		& \text{since } X \text{ is stochastically dominated by } N(\tau + \Delta(\alpha) + 2) \\
		& \\
		& \leq \mathbb{P}(X \leq \frac{\alpha m(\tau)}{2}) \\
		& \text{since } \alpha \geq 1 \\ % TODO: Check this assumption
	\end{align*}
	To finish the proof we prove the following claim

	\noindent
	\textbf{Claim.} For a Poisson($r$) distributed random random variable $Y$, 
	$$
		\mathbb{P}(Y \leq \frac{r}{2}) \leq e^{-cr}
	$$
	where $c$ is the constant defined in the statement of the theorem.

	\noindent
	\textit{Proof of Claim}

	\noindent
	From the definition of the density function of Poisson random variables we have that 
	\begin{align*}
		\mathbb{P}(Y \leq \frac{r}{2}) & = e^{-r} \sum_{j=0}^\frac{r}{2} \frac{r^j}{j!} \\ % TODO: Assumes r/2 is integer? 
		& = e^{-r} \sum_{j=0}^\frac{r}{2} \frac{2^j(\frac{r}{2})^j}{j!} \\
		& \leq e^{-r} \sum_{j=0}^\frac{r}{2} \frac{2^\frac{r}{2}(\frac{r}{2})^j}{j!} \\
		& \leq e^{-r} e^\frac{r \log 2}{2} \sum_{j=0}^\frac{r}{2} \frac{(\frac{r}{2})^j}{j!} \\
		& \leq e^{-r} e^\frac{r \log 2}{2} e^\frac{r}{2} \\
		& = e^{-r(\frac{1}{2} - \frac{\log2}{2})} \\ % TODO: Weaken constant?
	\end{align*}
	thus the claim is proved. Since $X \sim \text{Poisson}(\alpha m(\tau))$ we get that
	\begin{align*}
		\mathbb{P}(\tau' - \tau \geq \Delta(\alpha) + 2) \leq \mathbb{P}(X \leq \frac{\alpha m(\tau)}{2}) \leq e^{-c \alpha m(\tau)}
	\end{align*}	
\end{proof}

Now we iteratively apply Lemma \ref{AsyncIncreaseLemma} to derive the following Theorem.

\begin{theorem}
	\ModelIntro Then, with high probability, the rumour will have spread to all the nodes of $\mathcal{G}$ in time at most

	$$
		\min \left\{t : \sum_{k=0}^t \Phi(G_k)\rho(G_k) \geq C \log n \right\} 
	$$

	\noindent
	for a sufficiently large $C$
\end{theorem}

\begin{proof}
	We analyse the spread time in two phases. 

	% TODO: Add a of phase and intervals here, maybe plot m(t)

	\textbf{First Phase.} The first phase starts at time $t=0$ and ends at the first time when the number of informed nodes reaches $\frac{n}{2}$, which we denote $t_\text{half}$. We divide the phase into intervals $[\tau_i, \tau_{i+1}]$ where $\tau_0 = 0$ and $\tau_{i+1}$ is the first time the number of informed nodes increases by $\frac{m(\tau_i)}{2}$. 
	% TODO: MENTION FINAL INTERVAL MAY END AFTER t_\text{half}
	Using the notation from Lemma \ref{AsyncIncreaseLemma}, we have that $\tau_{i+1} = \tau_i'$. 
	
	Note that for all times $\tau < t_\text{half}$, the number of informed nodes is less than $\frac{n}{2}$, so $m(\tau) = |I_\tau|$. Thus, by the following induction at time $\tau_i < t_\text{half}$ there are at least $(\frac{3}{2})^i$ informed nodes.

	\underline{Base Case.}
	By algorithm \ref{NodeCentricAsyncAlgorithm} the rumour spreading starts at time 0 with a single node aware of the rumour. Thus $|I_{\tau_0}| = 1 = (\frac{3}{2})^0$

	\underline{Inductive Case.} 
	Assume that $\tau_i \geq (\frac{3}{2})^i$.
	From the definition of $\tau_i'$, we have that 
	\begin{align*}
		\tau_{i+1} &= \tau_i' \\
		&= \min\left\{\gamma : |I_{\gamma}| \geq |I_{\tau_i}| + \frac{m(\tau_i)}{2}\right\} \\
		&= \min\left\{\gamma : |I_{\gamma}| \geq |I_{\tau_i}| + \frac{|I_{\tau_i}|}{2}\right\} & \text{since } m(\tau_i) = |I_{\tau _i}| \text{ in this phase} \\ 
		&= \min\left\{\gamma : |I_{\gamma}| \geq \frac{3}{2}|I_{\tau_i}|\right\} 
	\end{align*}
	Thus $|I_{\tau_{i+1}}| \geq \frac{3}{2}|I_{\tau_i}| \geq \frac{3}{2}(\frac{3}{2})^i = (\frac{3}{2})^{i+1}$ by the induction hypothesis. 
	
	Let $K$ be the random variable for the index of the final interval in the phase, i.e the interval where $\tau_K < t_\text{half}$ and $\tau_{K+1} \geq t_\text{half}$.
	% TODO: TIMELINE FIGURE HERE
	Let $N = \ceil{\log_\frac{3}{2}\frac{n}{2}}$.  Since $|I_{\tau_i}| \geq (\frac{3}{2})^i$, we have that $|I_{\tau_N}| \geq (\frac{3}{2})^N \geq \frac{n}{2}$. Thus, $K < N$ otherwise the number of informed nodes at time $\tau_K$ would be greater than or equal to $\frac{n}{2}$, so $\tau_K$ would be at least $t_\text{half}$ which contradicts the definition of $K$.

	Let $\alpha_i = \ceil{\frac{c \log n}{c_0 (3/2)^i}}$. % TODO: Are c_0 and C defined? 
	By Lemma \ref{AsyncIncreaseLemma}, $\Delta(\alpha_i) + 2$ is an upper bound for the length of the interval $[\tau_i, \tau_{i+1}]$ 
	with probability at least $1 - e^{-c_0\alpha_i m(\tau_i)}$. %TODO: RESTRICT to i \leq K
	Since $m(\tau_i) = |I_{\tau_i}| \geq (\frac{3}{2})^i$, this probability is greater than $1 - e^{-c_0\alpha_i (\frac{3}{2})^i} \geq 1 - e^{-c \log n}$, by the definition of $\alpha_i$. By the union bound over all $K$ intervals of the phase,
	\begin{align*}
		& \mathbb{P}(\text{Any interval has length at least } \Delta(\alpha_i) + 2) \\
		&= \mathbb{P}(\bigcup_{i=0}^K \{\tau_{i+1} - \tau_i \geq \Delta(\alpha_i) + 2\}) \\
		&\leq \sum_{i=0}^K \mathbb{P}(\tau_{i+1} - \tau_i \geq \Delta(\alpha_i) + 2) \\
		&\leq \sum_{i=0}^K e^{-c \log n} \\
		&\leq \sum_{i=0}^N e^{-c \log n} 
		%% TODO: PUT IN REASONING& \text{since } K < N 
		\\
		&= N e^{-c \log n} \\
		&\to 0 \text { as } n \to \infty
	\end{align*}
	Thus with high probability all intervals have length at least $\Delta(\alpha_i) + 2$, hence
	\begin{align*}
		t_\text{half} &\leq \sum_{i=0}^K (\Delta(\alpha_i) + 2) \\
		&\leq \min \{t : blah \geq 2 \sum_{i=0}^K \alpha_i \} \\ % TODO: Justify this step
		&\leq \min \{t : blah \geq 2 \sum_{i=0}^N \alpha_i \} & %TODO: Mention \alpha_i need to be defined up to N
	\end{align*}

	\textbf{Second Phase.} The second phase starts at $t_\text{half}$, when at least $\frac{n}{2}$ nodes have been made aware of the rumour. The phase ends at the first time all nodes are aware of the rumour, which we denote $t_\text{all}$. We again divide up the phase into intervals $[\tau_j, \tau_{j+1}]$, where $\tau_0 = t_\text{half}$ and $\tau_{j+1} = \tau_j'$ as in the first phase.

	Note that since the number of informed nodes is at least $\frac{n}{2}$ during this is phase, the number of uniformed nodes is at most $\frac{n}{2}$. Thus for $\tau > t_\text{half}$, $m(\tau) = |U_\tau|$. Using this fact, we prove $|U_{\tau_j}| \leq n(\frac{1}{2})^{j+1}$ by induction.

	\underline{Base Case.}
	From the definition of $t_\text{half}$, $|I_{\tau_0}| = |I_{t_\text{half}}| \geq \frac{n}{2}$, so $|U_{\tau_0}| \leq n(\frac{1}{2})^{0+1}$.

	\underline{Inductive Case.} Suppose $|U_{\tau_j}| \leq n(\frac{1}{2})^{j+1}$. Note that since $|I_\tau| + |U_\tau| = n$, we have that $|I_{\gamma}| \geq |I_\tau| + \frac{m(\tau)}{2} \iff |U_\gamma| \leq |U_\tau| - \frac{m(\tau)}{2}$. Hence by the defintion of $\tau_j'$,
	\begin{align*}
		\tau_{j+1} &= \tau_j' \\
		&= \min \{ \gamma : |I_\gamma| \geq |I_{\tau_j}| + \frac{m(\tau_j)}{2}\} \\
		&= \min \{ \gamma : |U_\gamma| \leq |U_{\tau_j}| - \frac{m(\tau_j)}{2}\} \\
		&= \min \{ \gamma : |U_\gamma| \leq |U_{\tau_j}| - \frac{|U_{\tau_j}|}{2}\} & \text{since } m(\tau_j) = |U_{\tau_j}| \text{ in this phase} \\
		&= \min \{ \gamma : |U_\gamma| \leq \frac{1}{2}|U_{\tau_j}|\}
	\end{align*}
	Thus by the induction hypothesis, $|U_{\tau_{j+1}}| \leq \frac{1}{2}|U_{\tau_j}| \leq \frac{1}{2}n(\frac{1}{2})^{j+1} = n(\frac{1}{2})^{j+2}$.

	As in the first phase, let $K$ be the random variable for the index of the final interval in the phase, i.e the interval where $\tau_K < t_\text{all}$ and $\tau_{K+1} \geq t_\text{all}$.

	Let $M = \floor{\log_2 n}$. Since $|U_{\tau_j}| \leq n(\frac{1}{2})^{j+1}$, we have that $|U_{\tau_M}| \leq n(\frac{1}{2})^{M+1} \leq \frac{1}{2}$, thus since the number of informed nodes is an integer, at time $\tau_M$ there are no uninformed nodes left i.e all nodes are informed of the rumour. Hence $K < M$, otherwise at time $\tau_K$ all nodes would be aware of the rumour but we have that $\tau_K < t_\text{all}$ by the definition of $K$.

	Let $\beta_j = \ceil{\frac{c \log n}{c_0 n(1/2)^j}}$. % TODO: Are c_0 and C defined? 
	By Lemma \ref{AsyncIncreaseLemma}, $\Delta(\beta_i) + 2$ is an upper bound for the length of the interval $[\tau_j, \tau_{j+1}]$ 
	with probability at least $1 - e^{-c_0\beta_j m(\tau_j)}$. %TODO: RESTRICT to i \leq K
	Since $m(\tau_j) = |U_{\tau_j}| \leq n(\frac{1}{2})^{j+1}$.

\end{proof}
\subsection{Interpretation}

TODO

\begin{enumerate}
	\item Why diligence useful?
	\item When useful/better than other bounds?
	\item Comparison between absolute and non-absolute  diligence results, when is each useful?
\end{enumerate}

\subsection{Simulations}

TODO 

\begin{enumerate}
	\item Look at symmetrical graphs (complete, star, ring, path) and evaluate explicit bounds - evaluate tightness in each case with simulations
	\item Simulations for random graphs/evolutions
\end{enumerate}

\section{Proof that the asynchronous rumour spreading time bound is almost tight}
\label{section:AsyncLowerBound}

In this section, we prove that the upper bound derived in Section \ref{AsyncUpperBoundSection} is tight, by constructing an example where the spread time is close to the bound with high probability.

\begin{definition}\label{def:HkAB}
 	Graph $H_k(A,B)$

	Let $V$ be a set of $n$ vertices, with $A \subset V$ an arbitrary subset satisfying $\frac{n}{4} \leq |A| \leq \frac{3n}{4}$. Let B denote $V \setminus A$. Let $k = \mathcal{O}\left(\frac{\log n}{\log \log n}\right)$ and $\Delta = \mathcal{O}(\sqrt{n})$ be arbitrary positive integers. We construct the graph $H_k(A,B)$ on the vertex set $V$ using the following steps

	% TODO: Can we adjust k and delta slightly to work for k-regualr ends? 

	\textit{Step 1.} Let $\{S_i, 0 \leq i \leq k\}$ denote an arbitrary set of disjoint subsets of nodes in $V$ such that $|S_i| = \Delta$ for all $i$, $S_0 \subseteq A$ and $S_i \subseteq B$ for $1 \leq i \leq k$. We connect each node of $S_i$ to all nodes in $S_{i+1}$ for $0 \leq i \leq k - 1$. This generates a string of $k$ complete bipartite graphs, as seen in figure % TODO: REFBELOW

	%TODO: Graph after step 1 

	\textit{Step 2.} Let $G_A$ be an arbitrary m-regular %TODO: Fill in once decided on ending graphs
	graph on $A \setminus S_0$ such that $\Phi(G_A) = \Theta(1)$. %TODO: remove this??

	% TODO: m-regular graph 
	% https://sites.math.rutgers.edu/~sk1233/courses/topics-S13/lec8.pdf
	% Margulis–Gabber–Galil convert to simple graph?

	We now connect each node of $S_0$ to $\Delta$ distinct nodes of $G_A$. First, we arbitrarily enumerate the nodes in $S_0$ and $G_A$ as $v_1, v_2, \dots, v_\Delta$ and $u_1, u_2, \dots, u_{|G_A|}$ respectively. Connect $v_1$ to the first $\Delta$ nodes in the $G_A$, starting with $u_1$. Connect $v_2$ to the next $\Delta$ nodes in $G_A$, starting with $u_{\Delta + 1}$.
	Repeat this process for each $v_i$, as in figure % TODO: REF 
	If there are more new connections than nodes in $G_A$, reuse nodes in $G_A$ starting again from $u_1$ and forming new connections in the enumerated order, i.e the $i^\text{th}$ new connection should be made with node $u_m$ where $m = i\mod |G_A|$.

	\textit{Step 3.} Let $G_B$ be an arbitrary m-regular graph on $B \setminus \bigcup_{i=1}^k S_i$ such that $\Phi(G_B) = \Theta(1)$. 
	We generate $G_B$ using the same construction as in Step 2. We then connect each node of $S_k$ to $\Delta$ distinct nodes of $G_B$ using the same enumeration method as in Step 2. This yields the graph $H_k(A,B)$ illustrated in figure %TODO: REF

	% TODO: Final graph structure figure


	%TODO: explain how Winding around the ring increases the degree by at most an additive constant O(sqrt(n))^2 extra edges O(n) nodes in A \ S_0 so by O notation at most addivie constant difference

\end{definition}

We note that Definition \ref{def:HkAB} technically specifies a family of graphs, since the construction relies on choosing arbitrary permutations of vertices, each of which yields a distinct graph. However, for the purposes of this analysis we think of $H_k(A,B)$ as a single graph as all graphs in the family are isomorphic, and thus have the same structural properties needed for the proof. % TODO: Remove this paragraph? premature?

\begin{definition}
	$\rho$-diligent Dynamic Network
	
	First we define the sequences of node subsets $(A_t)_{t\geq 0}$ and $(B_t)_{t\geq0}$ with $A_t, B_t \subseteq V$ for all $t$. For each $t$, we construct $A_t$ and $B_t$ such that they partition $V$ into two subsets, as follows:

	Let $A_0$ be an arbitrary subset of $V$ of size $\ceil{\frac{n}{4}}$ containing the first node to be aware of the rumour. % TODO: Any problem with ceiling function?
	Set $B_0 = V \setminus A_0$. Let $B_{t+1} = B_t \setminus I_{t+1}$, i.e. the set of nodes in $B_t$ that were still not informed of the rumour by round $t+1$. Let $A_{t+1} = V \setminus A_t$, i.e. the set of nodes that were either in $A_0$ or informed of the rumour by round $t+1$.

	Now we can define the dynamic network $\rho$-diligent Dynamic Network $\mathcal{G}(n, \rho) = (G_t)_{t\geq 0}$ itself. 
	% TODO: Check sequnce notation consistent, 0 not in N
	% TODO: Does \Delta satisfy conditions required for H_\Delta(A,B)
	% TODO: Standardise notation for H_K(A,B)

	Let $\Delta = \ceil{\frac{1}{\rho}}$. Let $G_t = H_\Delta(A_t, B_t)$ while $|B_t| \geq \frac{n}{4}$. Note that $|B_t|$ is decreasing in $t$ since $B_t$ is a subset of the uniformed nodes at time $t$, so at some time step $l$ we have that $|B_l| < \frac{n}{4}$. For all time steps $t \geq l$, let $G_{t+1} = G_t$, since we cannot construct $H_\Delta(A,B)$ if $|B| < \frac{n}{4}$ as this would imply $|A| > \frac{3n}{4}$. % TODO: Reword ending$
\end{definition}

\section{Bounding the synchronous flooding time}
\label{SyncFloodingSection}

\subsection{Model}

\begin{definition} \label{SyncFloodingAlgorithm}
	Synchronous Flooding Rumour Spreading Algorithm

	\noindent
	The synchronous rumour spreading algorithm proceeds in rounds on a dynamic network $\mathcal{G} = (G_t)_{t \in \mathbb{N}}$. Initially a single node is aware of the rumour. In round $i$, every node that is aware of the rumour informs all of its neighbours in $G_i$, regardless of whether they already knew the rumour or not.
\end{definition}

We note that the asynchronous rumour spreading algorithm (algorithm \ref{NodeCentricAsyncAlgorithm}) was probabilistic since the algorithm depended on sources of randomness such as exponential clocks. In contrast, once the dynamic network and initial node from which the rumour spreads are chosen, algorithm \ref{SyncFloodingAlgorithm} is entirely deterministic. Since the trajectory of the rumour spread is completely determined by the initial conditions, it is reasonable to question why we would want bounds on the spreading time if we can simply simulate the rumour, and record how long it takes to inform all the nodes. However, some graphs may be so large that simulation is computationally infeasible. In such cases we need bounds in terms of the structural properties of graphs instead. Additionally, in section \ref{subsection:MEDNBound}
we analyse rumour spreading on a non-deterministic dynamic network, where the sequence of graphs is not fixed but instead follows some distribution. In this case, deterministic bounds will allow us to make claims about the spreading time over the distribution of graph sequences.

% TODO: Why study flooding time?
% Flooding only works for synchronus

\begin{definition}
	$(h, k)$-Expander

	\noindent
	A graph $G$ on a vertex set $V$ is a $(h, k)$-expander if for all subsets of nodes $S \subseteq V$ such that $|S| \leq h$ satisfy $|N(I)| \geq k$.
\end{definition}

\begin{definition}
	Boundary set $B(S)$

	\noindent 
	Given a graph $G=(V,E)$, the boundary set $B(S)$ of a vertex subset $S \subseteq V$ is defined as the set of vertices outside $S$ connected to a node of $S$ by an edge, i.e
	$$
		B(S) = \left\{u \in V \setminus S : \{u, v\} \in E \text{ for some } v \in S \right\}
	$$
\end{definition}

\subsection{Deriving the Deterministic Flooding Bound}

First we give a bound on the rumour spreading time for a deterministic sequence of graphs. 

\begin{theorem}\label{theorem:DeterministicFloodingBound}
	\ModelIntro Suppose also that there exists an increasing sequence $1 = h_0 \leq h_1 < \dots < h_s = \frac{n}{2}$ and decreasing sequence $k_1 \geq k_2 \geq \dots \geq k_s$ of positive real numbers, such that for all $t \in \mathbb{N}$, $G_t$ is a $(h_i, k_i)$-expander for every $i \in \{1, \dots , s\}$. Then the spreading time of $\mathcal{G}$ under algorithm \ref{SyncFloodingAlgorithm} is
	$$
		\mathcal{O}\left(\sum_{i=1}^s \frac{\log \frac{h_i}{h_{i-1}}}{\log(1+k_i)}\right)
	$$
\end{theorem}

% TODO: Strength of assumptions, why bother considering?

\begin{proof}
	For $i = 1,\dots, s$, let $T_i$ be the earliest time step such that the number of informed nodes is larger than $h_i$, i.e

	$$
		T_i = \min \{ t \in \mathbb{N} : |I_t| > h_i \}
	$$

	First we bound the number of steps in the interval $[T_{i-1}, T_i]$. If $T_{i-1} = T_i$ then the length of the interval is trivially 0, so suppose instead that $T_{i-1} < T_i$.

	By induction, we show that if $T_{i-1} + t < T_i$, then the number of informed nodes at time $T_{i-1} + t$ is greater than $(1+k_i)^t h_{i-1}$.
	
	\underline{Base Case.} Suppose that $t=0$. 
	
	Then by the definition of $T_{i-1}$, the number of informed nodes at time $T_{i-1}$ is strictly greater than $h_{i-1}$

	\underline{Inductive Case.} Suppose that $|I_{T_{i-1} + t}| > (1+k_i)^t h_{i-1}$.

	For brevity, let $s = T_{i-1} + t$. We notice that 
	% TODO: Justify steps
	% TODO: Define boundary of S, B(S)
	\begin{align*}
		|I_{s+1}| &= |I_s| + |B(I_s)| \\ %by operation of algo
		& \geq |I_s| + k_i |I_s| \\ % since we assume s < T_i => |I_s| \leq h_s + (h_s, k_s)-expander
		& = (1 + k_i)|I_s| \\
		& > (1 + k_i)(1+k_i)^t h_{i-1} \\ % by induction hypotheis
		& = (1+k_i)^{t+1} h_{i-1}
	\end{align*}
	% TODO: boundary set picture here	
	Let $\tau = T_{i-1} + \ceil{ \frac{\log (h_i/h_{i-1})}{\log(1+k_i)}}$. 
	Suppose for contradiction that $\tau < T_i$. %TODO: Is contradicition overkill here?
	Since we assumed $\tau < T_i$ we can apply the above inequality %TODO: label
	to get that 
	$$
		|I_\tau| > 
		(1+k_i)^{\ceil{ \frac{\log (h_i/h_{i-1})}{\log(1+k_i)}}} h_{i-1}
		\geq e^{\log (h_i/h_{i-1})} h_{i-1}
		= h_i
	$$
	Thus we have a contradiction since the number of informed nodes at time $\tau$ is greater than $h_i$, so $\tau \geq T_i$. Rearranging this inequality gives us the following bound on the length of the interval $[T_{i-1}, T_i]$:
	\begin{equation} \label{eq:FloodingSingleStepBound}
		T_i - T_{i-1} \leq \ceil{ \frac{\log (h_i/h_{i-1})}{\log(1+k_i)}} \leq \frac{\log (h_i/h_{i-1})}{\log(1+k_i)} + 1
	\end{equation}
	% TODO: Make ceiling brackets fit
	% TODO: Exposition about next steps + direction here
	We now apply our bound in two cases

	\textbf{Case 1.} Suppose $\frac{\log (h_i/h_{i-1})}{\log(1+k_i)} \geq 1$.

	In this case $\frac{\log (h_i/h_{i-1})}{\log(1+k_i)}$ term is the dominant term in inequality (\ref{eq:FloodingSingleStepBound}), thus
	$$
		T_i - T_{i-1} = \mathcal{O}\left( \frac{\log (h_i/h_{i-1})}{\log(1+k_i) }\right) + \mathcal{O}(1) = \mathcal{O}\left( \frac{\log (h_i/h_{i-1})}{\log(1+k_i) }\right)
	$$

	\textbf{Case 2.} Suppose $\frac{\log (h_i/h_{i-1})}{\log(1+k_i)} < 1$.

	In this case we cannot achieve the same bound on $T_i - T_{i-1}$, since the additive 1 is the dominant term. By following the same reasoning as in Case 1, we can only obtain
	\begin{equation}\label{eq:Weak1StepBound}
		T_i - T_{i-1} = \mathcal{O}\left( \frac{\log (h_i/h_{i-1})}{\log(1+k_i) }\right) + \mathcal{O}(1) = \mathcal{O}(1)
	\end{equation}
	To understand why this bound is weak, and derive a stronger one, we inspect the inequality we assumed in this case. % TODO: link back to this 
	By rearranging we find that $(1+k_i)h_{i-1} > h_i$. Since the minimum number of informed nodes after round $T_{i-1}$ is $(1+k_i)h_{i-1}$, we see that the number of informed nodes "jumps" to more than $h_i$ nodes in a single time step. % TODO: Wrong, fix this

	It may be that after this jump there are also more than $h_{i+k}$ nodes for some $k \geq 0$, from which we obtain $T_i = \dots = T_{i+k}$. In this case the total time that has passed between $T_{i-1}$ and $T_{i+k}$ is 0. However, using equation (\ref{eq:Weak1StepBound}) to bound even the first increment $T_{i-1}$ to $T_i$ gives the bound of $\mathcal{O}(1)$. We would prefer a much tighter bound, so instead bound the whole jump interval as follows. %TODO: Reprase end of this sentance
	
	% TODO: j doesn't exist case
	Let $j$ be the index such that $h_{j-1} < (1+k_i)h_{i-1} \leq h_j$, i.e the first $j \geq i$ when $T_j \neq T_{i-1}$. % TODO: Check this equivalence

	Note that from rearranging the definition of j
	\begin{align*}\label{eq:JumpBoundGeq1}
		1 &\leq \frac{\log (h_j) - \log(h_{i-1})}{\log(1+k_i) } \\
		& =\sum_{l=i}^j \frac{\log (h_{l}) - \log(h_{l-1})}{\log(1+k_i) } & \text{since the numerator forms a telescoping sum} \\
		& \leq \sum_{l=i}^j \frac{\log (h_{l}/h_{l-1})}{\log(1+k_l) } & \text{since the } k_i \text{s are a decreasing sequence and } i \leq l
	\end{align*}
	
	Hence, we can bound the length of the interval $[T_{i-1}, T_j]$ as follows.
	\begin{align*}
		T_j - T_{i-1} &= T_j - T_{j-1} & \text{since by the definition of j } T_{i-1} = T_{j-1}\\
		& \leq \frac{\log (h_j/h_{j-1})}{\log(1+k_i)} + 1 & \text{by applying inequality }(\ref{eq:FloodingSingleStepBound}) \\
		& \leq \frac{\log (h_j/h_{i-1})}{\log(1+k_i)} + 1 & \text{since the } h_i \text{s are increasing and } j \geq i \\
		& \leq \sum_{l=i}^j \frac{\log (h_{l}/h_{l-1})}{\log(1+k_l) } + 1 & \text{ by the previous inequality chain} \\
		& = \mathcal{O}\left(\sum_{l=i}^j \frac{\log (h_{l}/h_{l-1})}{\log(1+k_l) }\right)
 	\end{align*}
	where the final equality holds since by the previous inequality chain, the summation is greater than 1, so is the dominant term.

	We now use this equality to bound the growth of $T_s$, the first time at which more than $h_s = \frac{n}{2}$ nodes are aware of the rumour. We can express $T_s$ as a telescoping sum of intervals as follows:
	$$
		T_s = \sum_{i=1}^s T_i - T_{i-1}
	$$
	For the $i^\text{th}$ interval, if $\frac{\log (h_i/h_{i-1})}{\log(1+k_i)} \geq 1$, i.e. it takes at least one step then we can apply the bound from Case 1.
	
\end{proof}

\subsection{Review of Markov Chains}

\begin{enumerate}
	\item Definition
	\item Stationary distribution definition and Interpretation
\end{enumerate}

\subsection{Generalising the bound to Markovian Evolving Dynamic Networks}
\label{subsection:MEDNBound}

\begin{definition}
	Markovian Evolving Dynamic Network (MEDN)

	\noindent 
	Let $A_n$ be the set of all possible graphs on n vertices.
	A Markovian Evolving Dynamic Network is a random sequence of graphs $\mathcal{M} = (G_t)_{t \in \mathbb{N}}$ indexed by an integer time $t$, such that $\mathcal{G}$ is a Markov chain with state space $A_n$.
\end{definition}

We say that a given MEDN $\mathcal{M}$ is stationary if the distribution of $G_0$ is a stationary distribution of $\mathcal{M}$. By the definition of a stationary distribution, in such an MEDN the probability that $G_t = G'$ for a given $G'$ is the probability that $G_t = G'$ under the stationary distribution, for any time step $t$. Hence, the evolution of the network essentially proceeds by independently sampling a topology from the stationary distribution at each time step. % TODO: Check if independent, get rid of "essentially"?

% TODO: Is this a non-theorm? What does it acutally mean?

\begin{theorem}
	Let $\mathcal{M} = (G_t)_{t \in \mathbb{N}}$  be a stationary Markovian evolving graph. Suppose also that there exists an increasing sequence $1 = h_0 \leq h_1 < \dots < h_s = \frac{n}{2}$ and decreasing sequence $k_1 \geq k_2 \geq \dots \geq k_s$ of positive real numbers, such that with probability $1-\frac{1}{n^2}$, the stationary distribution of $\mathcal{M}$ is a $(h_i, k_i)$-expander for every $i \in \{1, \dots , s\}$. Then the spreading time of $\mathcal{G}$ under algorithm \ref{SyncFloodingAlgorithm} is
	$$
		\mathcal{O}\left(\sum_{i=1}^s \frac{\log \frac{h_i}{h_{i-1}}}{\log(1+k_i)}\right)
	$$
	with high probability.
\end{theorem}

We notice that in this theorem, instead of requiring every graph topology to satisfy the expansion conditions of Theorem \ref{theorem:DeterministicFloodingBound}, we only require that the expansion properties hold with high probability with respect to the stationary distribution. Since each topology is sampled from the stationary distribution, these properties will hold for nearly all the topologies in the sequence. Thus, this theorem states that our deterministic bound will still hold, as long as the long-term proportion of topologies in our network without strong expansion properties is bounded by $\frac{1}{n^2}$.

% TODO: Review this proof for order that makes sense, and check it actually holds

\begin{proof}
	For all $t \in \mathbb{N}$, let $A_t$ be the event that $G_t$ is an $(h_i, k_i)$-expander for all $1 \leq i \leq s$. Since $\mathcal{M}$ is stationary, we have that $\mathbb{P}(A_t) \geq 1 - \frac{1}{n^2}$ for all t. 

	Let $B$ denote the event we are interested in, namely that the rumour spreading time is 	
	$$
		\mathcal{O}\left(\sum_{i=1}^s \frac{\log \frac{h_i}{h_{i-1}}}{\log(1+k_i)}\right)
	$$

	Suppose that $A_k$ holds for all $k \leq n$. We claim that the rumour spreads in at most $n$ time steps with certainty. Since we have assumed that all topologies up to time $n$ are $(h_1, k_1)$-expanders, there are no isolated nodes, as such an isolated node $v$ would form a subset of size $1 \leq h_1$ with $B({v}) = 0 < k_1$, a contradiction. Thus, the network is connected for the first $n$ time steps. Hence, for any time step $t \leq n$ before all nodes are informed of the rumour, $B(I_t) \geq 1$, since there is only 1 connected component so $I_t$ must be connected  to $U_t$ by at least 1 edge. It follows that in each time step at least 1 new node becomes informed of the rumour by the operation of algorithm \ref{SyncFloodingAlgorithm}. Hence, at most $n$ steps are needed to spread the rumour when $A_k$ holds for all $k \leq n$. 

	Let $T$ denote the first time step at which all nodes are informed of the rumour. By Theorem \ref{theorem:DeterministicFloodingBound} we have that if $A_k$ holds for all $k \leq T$, then $T=\mathcal{O}\left(\sum_{i=1}^s \frac{\log (h_i/h_{i-1})}{\log(1+k_i)}\right)$, as once all the nodes have been informed, the expansion properties of the remaining topologies are irrelevant.

	Now we combine the previous two claims. By the first claim if $A_k$ holds for all $k \leq n$ we have that $T \leq n$, thus $A_k$ holds for all $k \leq T$. In this case, by the second claim we obtain that  $T=\mathcal{O}\left(\sum_{i=1}^s \frac{\log (h_i/h_{i-1})}{\log(1+k_i)}\right)$.

	Since we have shown that the event $\bigcap_{t=0}^n A_t \implies B$, we have that $\comp{B} \implies \comp{ \bigcap_{t=0}^n A_t} = \bigcup_{t=0}^n \comp{A_t}$. To finish the proof, we show that the event $\comp{B}$ happens with vanishing probability, thus $B$ happens with high probability.

	\begin{align*}
		\mathbb{P}(\comp{B}) &\leq \mathbb{P}(\bigcup_{t=0}^n \comp{A_t}) & \text{by the inferred implication} \\ 
		& \leq n \mathbb{P}(\comp{A_t}) & \text{by the union bound}\\ 
		& \leq n \frac{1}{n^2} = \frac{1}{n} & \text{by the conditions on the stationary distribution}
	\end{align*}

	% TODO: THINK ABOUT h_0

\end{proof}

\subsection{Applying the bound to Edge-Markovian evolution}

TODO: Prove that stationary distribution of edge-markovian evolution is ER G(n, p/(p+q))

\begin{theorem}
	Let $\mathcal{M}(n, p, q)$ be an Edge-Markovian Dynamic Network in its stationary distribution. If $p \geq c \frac{\log n}{n}$ for a sufficiently large $c$ then with high probability, the flooding time in $\mathcal{M}(n, p, q)$ is 

	$$
		\mathcal{O}\left(\frac{\log n}{\log np} + \log \log np \right)
	$$
\end{theorem}

TODO: Proof

\begin{proof}
	
\end{proof}

% TODO: What happens if p < c logn/n?
% lower bound on mixing time
% TODO: Why can't generalise to varying t? (Non-homogenous MC)

\subsection{Simulations}

TODO: Evaluate tightness of bound for Edge-Markovian evolution

\section{Bounding the asynchronous rumour spreading time in terms of the Cheeger constant}
\label{AsyncCheegerBound}

\subsection{Model}

TODO: Define asynchronous model - explain impact of changes in comparison to the other model (in this model each edge has rate 1 instead of 1/deg(v), bound not dependent on degrees of nodes)


Each edge is associated with a Poisson Process of unit rate. When the Possion Processes fires, if one of the endpoints knows the rumour then both endpoints immediately become aware of the rumour. 
% TODO: CHANGE WORDING - what if nodes know rumour already

\begin{definition}
	Edge-boundary of a set of vertices $A \subseteq V$
	$$
		\partial A = \left\{ \{u, v\} \in E \mid u \in A, v \in V \setminus A \right\} 
	$$
\end{definition}

\begin{definition}
	Cheeger Constant of a graph $G$
	$$
		h(G) = \min_{A \subset V, 0 < |A| \leq \frac{n}{2}} \frac{|\partial A|}{|A|}
	$$

\end{definition}

\begin{theorem}
	Let $\mathcal{G} = (G_t)_{t \in \mathbb{N}}$ be an $n$-node asychronus PUSH-model dynamic network, where at least one node is aware of a rumour in $G_0$.

	Then, with high probability, the rumour will have spread to all the nodes of $\mathcal{G}$ in time at most

	$$
		\min \left\{t : \sum_{k=0}^t h(G_k) \geq C \log n \right\} 
	$$

	\noindent
	for a sufficiently large $C$
\end{theorem}

TODO: Explain how can apply the following result in the proof from the first asychronus model

\begin{proof}

	% TODO: Move tau' defn to lemma statement
	Let $\tau'$ be the first time at which the number of informed nodes increases by at least $\frac{m(\tau)}{2}$ 
	
	$$
		\tau' = \min\left\{\gamma : |I_{\gamma}| \geq |I_\tau| + \frac{m(\tau)}{2}\right\}
	$$
	Let $ \gamma \in [\tau, \tau')$.

	Suppose  $|I_\gamma| \leq \frac{n}{2}$. By the definition of the Cheeger constant we have that $h(G_\gamma) \leq \frac{|\partial I_\gamma|}{|I_\gamma|}$. Note that $ \partial I_\gamma = E(I_\gamma, U_\gamma)$, since $\partial I_\gamma$ is the set of edges with exactly one endpoint in $I_\gamma$, thus the other endpoint must be in the complement of $I_\gamma$, namely $U_\gamma$. Thus

	\begin{align*}
		\lambda(\gamma) &= |E(I_\gamma, U_\gamma)| \\
		& = |\partial I_\gamma| \\
		& \geq h(G_\gamma) |I_\gamma| \\
		& \geq h(G_\gamma) |I_\tau| & \text{since } |I_\gamma| \text{ is increasing} \\
		& \geq h(G_\gamma) \frac{m(\tau)}{2}
	\end{align*}
		
	%TODO: THIS JUST EXCLUDES THE ERROR CASE
	Now suppose $|I_\gamma| > \frac{n}{2}$, thus $|U_\gamma| < \frac{n}{2}$. Hence, by the definition of the Cheeger constant we have that $h(G_\gamma) \leq \frac{|\partial U_\gamma|}{|U_\gamma|}$. Note that $ \partial U_\gamma = E(I_\gamma, U_\gamma)$, since $\partial U_\gamma$ is the set of edges with exactly one endpoint in $U_\gamma$,  thus the other endpoint must be in the complement of $U_\gamma$, namely $I_\gamma$. Thus 

	\begin{align*}
		\lambda(\gamma) &= |E(I_\gamma, U_\gamma)| \\
		& = |\partial U_\gamma| \\
		& \geq h(G_\gamma) |U_\gamma| \\
	\end{align*} 

	Since $|I_t| + |U_t| = n$ for all times $t$, we can reformulate the definition of $\tau'$ as follows

	$$
		\tau' = \min \left\{ \gamma : |U_\tau| - \frac{m(\tau)}{2} \geq |U_\gamma| \right\} 
	$$ 
	
	Since $\gamma < \tau'$ we have that

	\begin{align*}
		|U_\gamma| & \geq |U_\tau| - \frac{m(\tau)}{2} \\
		& \geq |U_\tau| - \frac{|U_\tau|}{2} \\
		& = \frac{|U_\tau|}{2} \\
	\end{align*}
	
	Hence $\lambda(\gamma) \geq h(G_\gamma)\frac{|U_\tau|}{2} = h(G_\gamma)\frac{m(\tau)}{2}$

\end{proof}

\subsection{Applying the bound to Edge-Markovian evolution}

TODO
\begin{enumerate}
	\item Prove that an individual G(n,p) ER graph satisfies $h(G) > p$ w.h.p
	\item Prove that the first log(n)/p ER graphs satisfy this property w.h.p (union bound on event at least one not satisfying)- see edge-markovian proof
	\item Combine with result from previous bound to get O(log(n)/p) concrete bound
	\item If possible - prove spread time is $\Theta(\log(n)/p)$
\end{enumerate}

\subsection{Simulations}

TODO: Evaluate bound with simulatons if can't prove spread time is  $\Theta(\log(n)/p)$

\section{Conclusion}

TODO:

\begin{enumerate}
	\item Summary of results
	\item Questions for further study
\end{enumerate}

\end{document}